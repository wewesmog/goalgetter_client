# Goalgetter Client

A production-ready productivity assistant that combines PydanticAI, MCP (Model Context Protocol), LangGraph, and Logfire for comprehensive goal, habit, and progress management.

## ğŸš€ Features

- **PydanticAI**: Structured AI responses with type safety
- **MCP Integration**: External tool integration for database operations
- **LangGraph**: Complex workflow orchestration with memory
- **Logfire**: Comprehensive observability and tracing
- **PostgreSQL**: Persistent conversation memory
- **FastAPI**: REST API for external access
- **CLI**: Command-line interface for testing and development

## ğŸ“ Detailed Project Structure

```
goalgetter-client/
â”œâ”€â”€ ğŸ“ config/                    # Configuration and settings
â”‚   â”œâ”€â”€ __init__.py              # Config module initialization
â”‚   â”œâ”€â”€ prompts.py               # System prompts for AI agents
â”‚   â””â”€â”€ settings.py              # Pydantic settings with environment variables
â”‚
â”œâ”€â”€ ğŸ“ src/                       # Main source code
â”‚   â”œâ”€â”€ __init__.py              # Source module initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ agents/               # AI agents and orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Agents module exports
â”‚   â”‚   â””â”€â”€ core.py              # ProductivityAgent & LangGraphOrchestrator
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/                  # FastAPI REST API
â”‚   â”‚   â”œâ”€â”€ __init__.py          # API module initialization
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app with endpoints
â”‚   â”‚   â””â”€â”€ models.py            # API request/response models
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ cli/                  # Command-line interface
â”‚   â”‚   â”œâ”€â”€ __init__.py          # CLI module exports
â”‚   â”‚   â””â”€â”€ cli.py               # Typer-based CLI commands
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/               # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Models module exports
â”‚   â”‚   â”œâ”€â”€ responses.py         # ProductivityResponse models
â”‚   â”‚   â””â”€â”€ schemas.py           # Database schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/             # External services
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Services module exports
â”‚   â”‚   â”œâ”€â”€ mcp_service.py       # MCP server integration
â”‚   â”‚   â”œâ”€â”€ memory_service.py    # PostgreSQL memory management
â”‚   â”‚   â””â”€â”€ conversation_service.py # Conversation context building
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                # Utility functions
â”‚       â”œâ”€â”€ __init__.py          # Utils module exports
â”‚       â”œâ”€â”€ logging.py           # Logfire setup and configuration
â”‚       â”œâ”€â”€ message_utils.py     # Message trimming and processing
â”‚       â””â”€â”€ token_utils.py       # Token counting utilities
â”‚
â”œâ”€â”€ ğŸ“ tests/                     # Test suite
â”‚   â””â”€â”€ __init__.py              # Test module initialization
â”‚
â”œâ”€â”€ ğŸ“ docs/                      # Documentation
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   # Deployment and utility scripts
â”‚
â”œâ”€â”€ ğŸ“„ mcp_client_pydantic.py    # Standalone MCP client (reference)
â”œâ”€â”€ ğŸ“„ test_api.py               # API testing script
â”œâ”€â”€ ğŸ“„ requirements.txt          # Production dependencies
â”œâ”€â”€ ğŸ“„ requirements-dev.txt      # Development dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml            # Project configuration
â”œâ”€â”€ ğŸ“„ Dockerfile                # Docker container configuration
â”œâ”€â”€ ğŸ“„ railway.toml              # Railway deployment config
â”œâ”€â”€ ğŸ“„ env.example               # Environment variables template
â””â”€â”€ ğŸ“„ README.md                 # This file
```

## ğŸ—ï¸ Architecture Overview

### Core Components

1. **ğŸ¤– Agents (`src/agents/`)**
   - `ProductivityAgent`: PydanticAI agent with MCP tools
   - `LangGraphOrchestrator`: Workflow orchestration with memory

2. **ğŸŒ API (`src/api/`)**
   - `main.py`: FastAPI application with chat endpoints
   - `models.py`: Request/response schemas

3. **ğŸ”§ Services (`src/services/`)**
   - `mcp_service.py`: MCP server integration for goalgetter
   - `memory_service.py`: PostgreSQL conversation memory
   - `conversation_service.py`: Context building and summarization

4. **ğŸ“Š Models (`src/models/`)**
   - `responses.py`: Structured AI response models
   - `schemas.py`: Database and API schemas

5. **ğŸ› ï¸ Utils (`src/utils/`)**
   - `logging.py`: Logfire observability setup
   - `message_utils.py`: Message trimming and processing
   - `token_utils.py`: Token counting and management

6. **âš™ï¸ Config (`config/`)**
   - `settings.py`: Environment-based configuration
   - `prompts.py`: AI system prompts

## ğŸ”„ Data Flow

```
User Request â†’ FastAPI â†’ LangGraph â†’ PydanticAI Agent â†’ MCP Tools â†’ Database
     â†“              â†“         â†“            â†“              â†“           â†“
   Response â† FastAPI â† LangGraph â† PydanticAI â† MCP Results â† Database
```

## ğŸ› ï¸ Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd goalgetter-client
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables:**
```bash
cp env.example .env
# Edit .env with your configuration
```

4. **Required environment variables:**
```env
OPENAI_API_KEY=your_openai_api_key
PGURL=postgresql://username:password@host:port/database
LOGFIRE_TOKEN=your_logfire_token
MCP_SERVER_PATH=D:\\goalgetter
```

## ğŸš€ Usage

### CLI Interface

**Interactive mode:**
```bash
python -m src.cli.cli interactive
```

**Test a single message:**
```bash
python -m src.cli.cli test "show me my goals"
```

**Check memory status:**
```bash
python -m src.cli.cli check-memory
```

**Start FastAPI server:**
```bash
python -m src.cli.cli serve
```

### FastAPI Server

**Start the server:**
```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

**API Documentation:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

**API Endpoints:**
- `POST /chat` - Send messages to the assistant
- `GET /memory/{user_id}` - Check memory status
- `GET /health` - Health check
- `GET /` - API information

### Example API Usage

**Send a chat message:**
```bash
curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{
       "message": "show me my goals",
       "user_id": "123"
     }'
```

**Check memory status:**
```bash
curl "http://localhost:8000/memory/123"
```

## ğŸ”§ Configuration

The application uses Pydantic Settings for configuration management. Key settings:

- **Performance**: Message trimming thresholds, token limits
- **Database**: PostgreSQL connection settings
- **Logging**: Logfire configuration
- **MCP**: Server path and timeout settings

## ğŸ“Š Observability

The application includes comprehensive observability through Logfire:

- **LLM Tracing**: Complete request/response visibility
- **Tool Calls**: MCP tool execution tracking
- **Performance**: Token usage and response times
- **Errors**: Detailed error logging and tracing

## ğŸ§ª Testing

**Run tests:**
```bash
pytest tests/
```

**Run with coverage:**
```bash
pytest --cov=src tests/
```

**Test API manually:**
```bash
python test_api.py
```

## ğŸš€ Deployment

### Railway Deployment

1. **Connect to Railway:**
```bash
railway login
railway init
```

2. **Set environment variables in Railway dashboard**

3. **Deploy:**
```bash
railway up
```

### Docker Deployment

**Build and run:**
```bash
docker build -t goalgetter-client .
docker run -p 8000:8000 --env-file .env goalgetter-client
```

## ğŸ” Development

**Install development dependencies:**
```bash
pip install -r requirements-dev.txt
```

**Code formatting:**
```bash
black src/
isort src/
```

**Type checking:**
```bash
mypy src/
```

**Linting:**
```bash
flake8 src/
```

## ğŸ“š Key Files Explained

### `src/agents/core.py`
- **ProductivityAgent**: Main AI agent with PydanticAI + MCP integration
- **LangGraphOrchestrator**: Manages conversation flow and memory
- **Message Trimming**: Automatically trims long conversations
- **Context Building**: Creates conversation summaries and context

### `src/api/main.py`
- **FastAPI Application**: REST API with chat endpoints
- **Lifespan Management**: Handles startup/shutdown with PostgreSQL
- **Error Handling**: Comprehensive error handling and logging
- **Response Formatting**: Clean response extraction from PydanticAI

### `src/services/mcp_service.py`
- **MCP Integration**: Connects to goalgetter MCP server
- **Tool Management**: Handles MCP tool calls and responses
- **Error Handling**: Robust MCP connection management

### `src/services/memory_service.py`
- **PostgreSQL Memory**: Manages conversation persistence
- **Checkpointer Setup**: Configures LangGraph memory
- **Memory Fallback**: Falls back to in-memory if PostgreSQL fails

### `config/settings.py`
- **Environment Variables**: All configuration via .env file
- **Pydantic Settings**: Type-safe configuration management
- **Performance Tuning**: Message trimming and token limits

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For support and questions:
- Create an issue in the repository
- Check the documentation in `/docs`
- Review the API documentation at `/docs` when running the server